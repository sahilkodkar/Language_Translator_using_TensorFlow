{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# English to French Translator using TensorFlow"
      ],
      "metadata": {
        "id": "2eGoIoZAAAR5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "biFTr8je_NDy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras. models import Model, Sequential\n",
        "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Dropout, LSTM, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Data\n",
        "english_data = '/content/Language Translation Files/small_vocab_en.txt'\n",
        "french_data = '/content/Language Translation Files/small_vocab_fr.txt'"
      ],
      "metadata": {
        "id": "X4huCn82MfLW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def load_data(path):\n",
        "  input_file = os.path.join(path)\n",
        "  with open(input_file, 'r') as f:\n",
        "    data = f.read()\n",
        "  return data.split('\\n')"
      ],
      "metadata": {
        "id": "EiAZCIQtM6P_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_sentences = load_data(english_data)\n",
        "french_sentences = load_data(french_data)"
      ],
      "metadata": {
        "id": "J3RiKAKLN_h-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print('Sample:', i)\n",
        "  print(english_sentences[i])\n",
        "  print(french_sentences[i])\n",
        "  print('-'*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW1IpqZgOWM_",
        "outputId": "50b35e16-097c-4e91-a766-c2fc9ec878cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample: 0\n",
            "new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
            "new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
            "--------------------------------------------------\n",
            "Sample: 1\n",
            "the united states is usually chilly during july , and it is usually freezing in november .\n",
            "les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n",
            "--------------------------------------------------\n",
            "Sample: 2\n",
            "california is usually quiet during march , and it is usually hot in june .\n",
            "california est généralement calme en mars , et il est généralement chaud en juin .\n",
            "--------------------------------------------------\n",
            "Sample: 3\n",
            "the united states is sometimes mild during june , and it is cold in september .\n",
            "les états-unis est parfois légère en juin , et il fait froid en septembre .\n",
            "--------------------------------------------------\n",
            "Sample: 4\n",
            "your least liked fruit is the grape , but my least liked is the apple .\n",
            "votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert to Vocabulary"
      ],
      "metadata": {
        "id": "bPdgKIqbPEO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections"
      ],
      "metadata": {
        "id": "w7eEFjlGOzO3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting words using counter function\n",
        "english_words_counter = collections.Counter([word for sentences in english_sentences for word in sentences.split()])\n",
        "print('English Vocab : ', len(english_words_counter))\n",
        "french_words_counter = collections.Counter([word for sentences in french_sentences for word in sentences.split()])\n",
        "print('French Vocab : ', len(french_words_counter))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI6n4Rl1Prgj",
        "outputId": "2cf69a01-80cf-4e54-83d5-09a5f3e05c7c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Vocab :  227\n",
            "French Vocab :  355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize"
      ],
      "metadata": {
        "id": "qJB55_faUI-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(x):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(x)\n",
        "  return tokenizer.texts_to_sequences(x), tokenizer"
      ],
      "metadata": {
        "id": "NBn8-FMZSIYF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_sentences = [\n",
        "  'The quick brown fox jumps over the lazy dog.',\n",
        "  'By Jove, my quick study of lexicography won a prize.',\n",
        "  'This is a short sentence.']\n",
        "\n",
        "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
        "print(text_tokenizer.word_index)\n",
        "print()\n",
        "\n",
        "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n",
        "  print('Sequence {} in x'.format(sample_i, 1))\n",
        "  print('Input: {}'.format(sent))\n",
        "  print('Output: {}'.format(token_sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA2noSCsUgK8",
        "outputId": "607444b7-edf2-44d2-923c-041cc3318a95"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 1, 'quick': 2, 'a': 3, 'brown': 4, 'fox': 5, 'jumps': 6, 'over': 7, 'lazy': 8, 'dog': 9, 'by': 10, 'jove': 11, 'my': 12, 'study': 13, 'of': 14, 'lexicography': 15, 'won': 16, 'prize': 17, 'this': 18, 'is': 19, 'short': 20, 'sentence': 21}\n",
            "\n",
            "Sequence 0 in x\n",
            "Input: The quick brown fox jumps over the lazy dog.\n",
            "Output: [1, 2, 4, 5, 6, 7, 1, 8, 9]\n",
            "Sequence 1 in x\n",
            "Input: By Jove, my quick study of lexicography won a prize.\n",
            "Output: [10, 11, 12, 2, 13, 14, 15, 16, 3, 17]\n",
            "Sequence 2 in x\n",
            "Input: This is a short sentence.\n",
            "Output: [18, 19, 3, 20, 21]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Padding"
      ],
      "metadata": {
        "id": "q2sofbsMmZb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pad(x, length=None):\n",
        "  return pad_sequences(x, maxlen=length, padding='post')"
      ],
      "metadata": {
        "id": "_7FdFGOvl1GQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(x, y):\n",
        "  # Preprocess\n",
        "  preprocess_x, x_tk = tokenize(x)\n",
        "  preprocess_y, y_tk = tokenize(y)\n",
        "  # Padding\n",
        "  preprocess_x = pad(preprocess_x)\n",
        "  preprocess_y = pad(preprocess_y)\n",
        "\n",
        "  # Expanding dimensions for keras sparse_categorical_crossentropy that requires 3 dimensions\n",
        "  preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
        "  return preprocess_x, preprocess_y, x_tk, y_tk\n",
        "\n",
        "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer = preprocess(english_sentences, french_sentences)\n",
        "\n",
        "# Max sentence length\n",
        "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
        "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
        "# Len of vocabulary\n",
        "english_vocab_size = len(english_tokenizer.word_index)\n",
        "french_vocab_size = len(french_tokenizer.word_index)\n",
        "\n",
        "print('Data Processed')\n",
        "print('Max english sentence length: ', max_english_sequence_length)\n",
        "print('Max french sentence length: ', max_french_sequence_length)\n",
        "print('English vocabulary size: ', english_vocab_size)\n",
        "print('French vocabulary size: ', french_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNKvILCqnKWy",
        "outputId": "d2f845d4-e3a3-4b85-e1d2-c60e2e1d8feb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Processed\n",
            "Max english sentence length:  15\n",
            "Max french sentence length:  21\n",
            "English vocabulary size:  199\n",
            "French vocabulary size:  344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "b3oLk6QguXf5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IDs back to text"
      ],
      "metadata": {
        "id": "wlyuKvdE0ugR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logits_to_text(logits, tokenizer):\n",
        "  # Dictionray which maps each word to its correspnding ids\n",
        "  # Then uses it to find all words with ids 0-9 and prints them\n",
        "  index_to_words = {id: word for word , id in tokenizer.word_index.items()}\n",
        "  index_to_words[0] = '<PAD>'\n",
        "\n",
        "  # Predicting model for given word and selecting the best answer, then reverse enumerate the word from the id\n",
        "  return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])"
      ],
      "metadata": {
        "id": "LHOiwDlAtacl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Model"
      ],
      "metadata": {
        "id": "8155RyR800Jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "  '''\n",
        "  Build and train an RNN model using word embedding on x and y\n",
        "  :param input_shape: Tuple of input shape\n",
        "  :param output_sequence length: Length of output sequence\n",
        "  :param english_vocab_size: Number of unique english words in dataset\n",
        "  :param french_vocab_size: Number of unique french words in the dataset\n",
        "  '''\n",
        "\n",
        "  learning_rate = 0.005\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Embedding(english_vocab_size, 256, input_length=input_shape[1], input_shape=input_shape[1:]))\n",
        "  model.add(GRU(256, return_sequences=True))\n",
        "  model.add(TimeDistributed(Dense(1024, activation='relu')))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax')))\n",
        "\n",
        "  model.compile(loss=sparse_categorical_crossentropy,\n",
        "                optimizer=Adam(learning_rate),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "1F8Mdo4I0qr7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping the input to work with basic RNN\n",
        "\n",
        "tmp_x = pad(preproc_english_sentences, preproc_french_sentences.shape[1])\n",
        "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))"
      ],
      "metadata": {
        "id": "J4rtZmDvCx2L"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_rnn_model = embed_model(\n",
        "    tmp_x.shape,\n",
        "    preproc_french_sentences.shape[-1],\n",
        "    len(english_tokenizer.word_index)+1,\n",
        "    len(french_tokenizer.word_index)+1\n",
        ")"
      ],
      "metadata": {
        "id": "Xvj9w-LiEFUI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_rnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKWmnmWbFm_y",
        "outputId": "1cae0ade-2a42-44e4-b51d-7ac21366f3a9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 21, 256)           51200     \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 21, 256)           394752    \n",
            "                                                                 \n",
            " time_distributed (TimeDist  (None, 21, 1024)          263168    \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 21, 1024)          0         \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDi  (None, 21, 345)           353625    \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1062745 (4.05 MB)\n",
            "Trainable params: 1062745 (4.05 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "7XWkKDHBGR2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = simple_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "redR3yOxFtiO",
        "outputId": "804a7bef-43ea-40af-b2cb-a57a779d48e4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "108/108 [==============================] - 39s 345ms/step - loss: 1.3699 - accuracy: 0.6799 - val_loss: 0.4845 - val_accuracy: 0.8436\n",
            "Epoch 2/20\n",
            "108/108 [==============================] - 36s 334ms/step - loss: 0.4080 - accuracy: 0.8659 - val_loss: 0.2973 - val_accuracy: 0.8992\n",
            "Epoch 3/20\n",
            "108/108 [==============================] - 36s 332ms/step - loss: 0.2923 - accuracy: 0.9026 - val_loss: 0.2421 - val_accuracy: 0.9178\n",
            "Epoch 4/20\n",
            "108/108 [==============================] - 36s 334ms/step - loss: 0.2446 - accuracy: 0.9174 - val_loss: 0.2171 - val_accuracy: 0.9254\n",
            "Epoch 5/20\n",
            "108/108 [==============================] - 36s 330ms/step - loss: 0.2201 - accuracy: 0.9241 - val_loss: 0.2008 - val_accuracy: 0.9298\n",
            "Epoch 6/20\n",
            "108/108 [==============================] - 36s 336ms/step - loss: 0.2046 - accuracy: 0.9287 - val_loss: 0.1986 - val_accuracy: 0.9302\n",
            "Epoch 7/20\n",
            "108/108 [==============================] - 37s 340ms/step - loss: 0.1952 - accuracy: 0.9312 - val_loss: 0.1883 - val_accuracy: 0.9330\n",
            "Epoch 8/20\n",
            "108/108 [==============================] - 36s 337ms/step - loss: 0.1885 - accuracy: 0.9331 - val_loss: 0.1845 - val_accuracy: 0.9349\n",
            "Epoch 9/20\n",
            "108/108 [==============================] - 36s 334ms/step - loss: 0.1840 - accuracy: 0.9345 - val_loss: 0.1828 - val_accuracy: 0.9357\n",
            "Epoch 10/20\n",
            "108/108 [==============================] - 37s 339ms/step - loss: 0.1794 - accuracy: 0.9356 - val_loss: 0.1792 - val_accuracy: 0.9363\n",
            "Epoch 11/20\n",
            "108/108 [==============================] - 37s 339ms/step - loss: 0.1768 - accuracy: 0.9364 - val_loss: 0.1824 - val_accuracy: 0.9357\n",
            "Epoch 12/20\n",
            "108/108 [==============================] - 36s 337ms/step - loss: 0.1732 - accuracy: 0.9373 - val_loss: 0.1771 - val_accuracy: 0.9374\n",
            "Epoch 13/20\n",
            "108/108 [==============================] - 36s 338ms/step - loss: 0.1706 - accuracy: 0.9380 - val_loss: 0.1805 - val_accuracy: 0.9361\n",
            "Epoch 14/20\n",
            "108/108 [==============================] - 37s 341ms/step - loss: 0.1724 - accuracy: 0.9375 - val_loss: 0.1808 - val_accuracy: 0.9364\n",
            "Epoch 15/20\n",
            "108/108 [==============================] - 36s 337ms/step - loss: 0.1707 - accuracy: 0.9380 - val_loss: 0.1783 - val_accuracy: 0.9374\n",
            "Epoch 16/20\n",
            "108/108 [==============================] - 36s 336ms/step - loss: 0.1658 - accuracy: 0.9393 - val_loss: 0.1750 - val_accuracy: 0.9394\n",
            "Epoch 17/20\n",
            "108/108 [==============================] - 35s 328ms/step - loss: 0.1660 - accuracy: 0.9392 - val_loss: 0.1763 - val_accuracy: 0.9383\n",
            "Epoch 18/20\n",
            "108/108 [==============================] - 36s 331ms/step - loss: 0.1699 - accuracy: 0.9384 - val_loss: 0.1839 - val_accuracy: 0.9365\n",
            "Epoch 19/20\n",
            "108/108 [==============================] - 36s 333ms/step - loss: 0.1681 - accuracy: 0.9387 - val_loss: 0.1791 - val_accuracy: 0.9387\n",
            "Epoch 20/20\n",
            "108/108 [==============================] - 36s 332ms/step - loss: 0.1622 - accuracy: 0.9402 - val_loss: 0.1802 - val_accuracy: 0.9382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving Model\n",
        "simple_rnn_model.save('model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu7QMCFaGrgS",
        "outputId": "263ac033-a5e5-438d-88cb-79bef31ac028"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arbitrary Predictions\n",
        "### Performing predictions on the models using user input."
      ],
      "metadata": {
        "id": "P5w-bdGlQupO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "english_tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuS0kbRFQ9ZG",
        "outputId": "030cf907-d3bf-4dca-e3d2-31045c1ccdb0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'is': 1,\n",
              " 'in': 2,\n",
              " 'it': 3,\n",
              " 'during': 4,\n",
              " 'the': 5,\n",
              " 'but': 6,\n",
              " 'and': 7,\n",
              " 'sometimes': 8,\n",
              " 'usually': 9,\n",
              " 'never': 10,\n",
              " 'favorite': 11,\n",
              " 'least': 12,\n",
              " 'fruit': 13,\n",
              " 'most': 14,\n",
              " 'loved': 15,\n",
              " 'liked': 16,\n",
              " 'new': 17,\n",
              " 'paris': 18,\n",
              " 'india': 19,\n",
              " 'united': 20,\n",
              " 'states': 21,\n",
              " 'california': 22,\n",
              " 'jersey': 23,\n",
              " 'france': 24,\n",
              " 'china': 25,\n",
              " 'he': 26,\n",
              " 'she': 27,\n",
              " 'grapefruit': 28,\n",
              " 'your': 29,\n",
              " 'my': 30,\n",
              " 'his': 31,\n",
              " 'her': 32,\n",
              " 'fall': 33,\n",
              " 'june': 34,\n",
              " 'spring': 35,\n",
              " 'january': 36,\n",
              " 'winter': 37,\n",
              " 'march': 38,\n",
              " 'autumn': 39,\n",
              " 'may': 40,\n",
              " 'nice': 41,\n",
              " 'september': 42,\n",
              " 'july': 43,\n",
              " 'april': 44,\n",
              " 'november': 45,\n",
              " 'summer': 46,\n",
              " 'december': 47,\n",
              " 'february': 48,\n",
              " 'our': 49,\n",
              " 'their': 50,\n",
              " 'freezing': 51,\n",
              " 'pleasant': 52,\n",
              " 'beautiful': 53,\n",
              " 'october': 54,\n",
              " 'snowy': 55,\n",
              " 'warm': 56,\n",
              " 'cold': 57,\n",
              " 'wonderful': 58,\n",
              " 'dry': 59,\n",
              " 'busy': 60,\n",
              " 'august': 61,\n",
              " 'chilly': 62,\n",
              " 'rainy': 63,\n",
              " 'mild': 64,\n",
              " 'wet': 65,\n",
              " 'relaxing': 66,\n",
              " 'quiet': 67,\n",
              " 'hot': 68,\n",
              " 'dislikes': 69,\n",
              " 'likes': 70,\n",
              " 'limes': 71,\n",
              " 'lemons': 72,\n",
              " 'grapes': 73,\n",
              " 'mangoes': 74,\n",
              " 'apples': 75,\n",
              " 'peaches': 76,\n",
              " 'oranges': 77,\n",
              " 'pears': 78,\n",
              " 'strawberries': 79,\n",
              " 'bananas': 80,\n",
              " 'to': 81,\n",
              " 'grape': 82,\n",
              " 'apple': 83,\n",
              " 'orange': 84,\n",
              " 'lemon': 85,\n",
              " 'lime': 86,\n",
              " 'banana': 87,\n",
              " 'mango': 88,\n",
              " 'pear': 89,\n",
              " 'strawberry': 90,\n",
              " 'peach': 91,\n",
              " 'like': 92,\n",
              " 'dislike': 93,\n",
              " 'they': 94,\n",
              " 'that': 95,\n",
              " 'i': 96,\n",
              " 'we': 97,\n",
              " 'you': 98,\n",
              " 'animal': 99,\n",
              " 'a': 100,\n",
              " 'truck': 101,\n",
              " 'car': 102,\n",
              " 'automobile': 103,\n",
              " 'was': 104,\n",
              " 'next': 105,\n",
              " 'go': 106,\n",
              " 'driving': 107,\n",
              " 'visit': 108,\n",
              " 'little': 109,\n",
              " 'big': 110,\n",
              " 'old': 111,\n",
              " 'yellow': 112,\n",
              " 'red': 113,\n",
              " 'rusty': 114,\n",
              " 'blue': 115,\n",
              " 'white': 116,\n",
              " 'black': 117,\n",
              " 'green': 118,\n",
              " 'shiny': 119,\n",
              " 'are': 120,\n",
              " 'last': 121,\n",
              " 'feared': 122,\n",
              " 'animals': 123,\n",
              " 'this': 124,\n",
              " 'plan': 125,\n",
              " 'going': 126,\n",
              " 'saw': 127,\n",
              " 'disliked': 128,\n",
              " 'drives': 129,\n",
              " 'drove': 130,\n",
              " 'between': 131,\n",
              " 'translate': 132,\n",
              " 'plans': 133,\n",
              " 'were': 134,\n",
              " 'went': 135,\n",
              " 'might': 136,\n",
              " 'wanted': 137,\n",
              " 'thinks': 138,\n",
              " 'spanish': 139,\n",
              " 'portuguese': 140,\n",
              " 'chinese': 141,\n",
              " 'english': 142,\n",
              " 'french': 143,\n",
              " 'translating': 144,\n",
              " 'difficult': 145,\n",
              " 'fun': 146,\n",
              " 'easy': 147,\n",
              " 'wants': 148,\n",
              " 'think': 149,\n",
              " 'why': 150,\n",
              " \"it's\": 151,\n",
              " 'did': 152,\n",
              " 'cat': 153,\n",
              " 'shark': 154,\n",
              " 'bird': 155,\n",
              " 'mouse': 156,\n",
              " 'horse': 157,\n",
              " 'elephant': 158,\n",
              " 'dog': 159,\n",
              " 'monkey': 160,\n",
              " 'lion': 161,\n",
              " 'bear': 162,\n",
              " 'rabbit': 163,\n",
              " 'snake': 164,\n",
              " 'when': 165,\n",
              " 'want': 166,\n",
              " 'do': 167,\n",
              " 'how': 168,\n",
              " 'elephants': 169,\n",
              " 'horses': 170,\n",
              " 'dogs': 171,\n",
              " 'sharks': 172,\n",
              " 'snakes': 173,\n",
              " 'cats': 174,\n",
              " 'rabbits': 175,\n",
              " 'monkeys': 176,\n",
              " 'bears': 177,\n",
              " 'birds': 178,\n",
              " 'lions': 179,\n",
              " 'mice': 180,\n",
              " \"didn't\": 181,\n",
              " 'eiffel': 182,\n",
              " 'tower': 183,\n",
              " 'grocery': 184,\n",
              " 'store': 185,\n",
              " 'football': 186,\n",
              " 'field': 187,\n",
              " 'lake': 188,\n",
              " 'school': 189,\n",
              " 'would': 190,\n",
              " \"aren't\": 191,\n",
              " 'been': 192,\n",
              " 'weather': 193,\n",
              " 'does': 194,\n",
              " 'has': 195,\n",
              " \"isn't\": 196,\n",
              " 'am': 197,\n",
              " 'where': 198,\n",
              " 'have': 199}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def final_predictions(text):\n",
        "  y_id_to_word = {value: key for key, value in french_tokenizer.word_index.items()}\n",
        "  y_id_to_word[0] = '<PAD>'\n",
        "\n",
        "  sentence = [english_tokenizer.word_index[word] for word in text.split()]\n",
        "  sentence = pad_sequences([sentence], maxlen=preproc_french_sentences.shape[-2], padding='post')\n",
        "  text1 = logits_to_text(simple_rnn_model.predict(sentence[:1])[0], french_tokenizer)\n",
        "  text2 = ''\n",
        "\n",
        "  for i in text1.split():\n",
        "    if i=='<PAD>':\n",
        "      break\n",
        "    else:\n",
        "      text2=text2+' '+i\n",
        "  return text2"
      ],
      "metadata": {
        "id": "rWWyO5tQRJ99"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_predictions(input())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "aF2bylBoUc1Y",
        "outputId": "c1b4d1c5-b05f-419e-aba2-fdbdd77c1a3c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most loved fruit\n",
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' fruit le plus aimé'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wc3CXfF7XARz",
        "outputId": "109d5883-8649-4d7b-8f83-439a77c122f7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.36.1-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==1.0.1 (from gradio)\n",
            "  Downloading gradio_client-1.0.1-py3-none-any.whl (318 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.4)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.3.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.4)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.4.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.0.1->gradio) (2024.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==1.0.1->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.22.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->gradio)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=cc24782492d698e11d8a1ea56e8252aafc64df860ea5184e580d3e811a2934a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uvloop, ujson, tomlkit, semantic-version, ruff, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, aiofiles, watchfiles, uvicorn, starlette, httpcore, email_validator, httpx, gradio-client, fastapi-cli, fastapi, gradio\n",
            "Successfully installed aiofiles-23.2.1 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 gradio-4.36.1 gradio-client-1.0.1 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 orjson-3.10.5 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.4.10 semantic-version-2.10.0 starlette-0.37.2 tomlkit-0.12.0 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "k04zWCNSaWZh"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interface = gr.Interface(fn=final_predictions,\n",
        "             inputs=gr.Textbox(lines=2, placeholder='Text to translate'),\n",
        "            outputs=gr.Textbox())\n",
        "\n",
        "interface.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "PHiFPeKga-lX",
        "outputId": "0861aaf5-bf12-439a-9f87-fc21d49ddb9f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://9c521a7f6635970ec3.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9c521a7f6635970ec3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 29ms/step\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://9c521a7f6635970ec3.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ]
}